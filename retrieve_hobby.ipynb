{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in /Users/michellesi/anaconda3/lib/python3.10/site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in /Users/michellesi/anaconda3/lib/python3.10/site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: python-dotenv in /Users/michellesi/anaconda3/lib/python3.10/site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in /Users/michellesi/anaconda3/lib/python3.10/site-packages (from webdriver-manager) (22.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/michellesi/anaconda3/lib/python3.10/site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/michellesi/anaconda3/lib/python3.10/site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/michellesi/anaconda3/lib/python3.10/site-packages (from requests->webdriver-manager) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/michellesi/anaconda3/lib/python3.10/site-packages (from requests->webdriver-manager) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Too many arguments for typing.List; actual 2, expected 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m SEARCH_ENGINE_ID \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEARCH_ENGINE_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Define Faculty model with additional fields for GPT-generated data\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFaculty\u001b[39;00m(BaseModel):\n\u001b[1;32m     35\u001b[0m     research_interests_paragraph: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m     36\u001b[0m     research_interests_as_commaseparated_list: List[\u001b[38;5;28mstr\u001b[39m]\n",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m, in \u001b[0;36mFaculty\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m research_interests_as_commaseparated_list: List[\u001b[38;5;28mstr\u001b[39m]\n\u001b[1;32m     37\u001b[0m hobbies: \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m---> 38\u001b[0m hobbies_as_commaseparated_list_with_references: \u001b[43mList\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m personal_website_url: \u001b[38;5;28mstr\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/typing.py:312\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/typing.py:1144\u001b[0m, in \u001b[0;36m_SpecialGenericAlias.__getitem__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1142\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters to generic types must be types.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1143\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_type_check(p, msg) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params)\n\u001b[0;32m-> 1144\u001b[0m \u001b[43m_check_generic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_with(params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/typing_extensions.py:2911\u001b[0m, in \u001b[0;36m_check_generic\u001b[0;34m(cls, parameters, elen)\u001b[0m\n\u001b[1;32m   2908\u001b[0m         expect_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2910\u001b[0m things \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2911\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmany\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39malen\u001b[38;5;250m \u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;250m \u001b[39melen\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfew\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthings\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2912\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; actual \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpect_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Too many arguments for typing.List; actual 2, expected 1"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "%pip install webdriver-manager\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from typing import List, Literal, Optional, Tuple\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "import threading\n",
    "from functools import partial\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "SEARCH_ENGINE_ID = os.getenv(\"SEARCH_ENGINE_ID\")\n",
    "\n",
    "# Define Faculty model with additional fields for GPT-generated data\n",
    "class Faculty(BaseModel):\n",
    "    research_interests_paragraph: str\n",
    "    research_interests_as_commaseparated_list: List[str]\n",
    "    hobbies: str\n",
    "    hobbies_as_commaseparated_list_with_references: List[Tuple[str, str]]\n",
    "    personal_website_url: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.cs.princeton.edu/people/profile/ltliu', 'https://www.lydiatliu.com/', 'https://csweb-prod-old.cs.princeton.edu/people/profile/ltliu', 'https://citp.princeton.edu/citp-people/lydia-liu/', 'https://csweb-prod-old.cs.princeton.edu/news/lydia-liu-expert-social-impacts-machine-learning-has-joined-faculty', 'https://gradfutures.princeton.edu/grad-stories/lydia-t-liu', 'https://citp.princeton.edu/lydia-liu-has-joined-the-faculty/', 'https://scholar.google.com/citations?user=IQ2eTA8AAAAJ']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from typing import List\n",
    "import time\n",
    "\n",
    "def search(query: str) -> List[str]:\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Enable headless mode\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    try:\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.get(\"https://html.duckduckgo.com/html/\")\n",
    "        \n",
    "        # Find and fill search box\n",
    "        search_box = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"q\"))\n",
    "        )\n",
    "        search_box.send_keys(query + \"MIT professor\")\n",
    "        search_box.submit()\n",
    "        \n",
    "        # Wait for results and extract links\n",
    "        time.sleep(2)  # Allow time for results to load\n",
    "        results = driver.find_elements(By.CSS_SELECTOR, \"a.result__a\")\n",
    "        \n",
    "        links = []\n",
    "        for result in results[:8]:  # Get first 8 results\n",
    "            links.append(result.get_attribute('href'))\n",
    "            \n",
    "        return links\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during DuckDuckGo search for query '{query}': {e}\")\n",
    "        return []\n",
    "        \n",
    "    finally:\n",
    "        if 'driver' in locals():\n",
    "            driver.quit()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Test the function\n",
    "#     results = search(\"Lydia liu princeton cs\")\n",
    "#     print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 97\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m links \u001b[38;5;241m=\u001b[39m \u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlydia liu princeton cs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(links)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_text_w_google\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m, max_chars: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]]:\n",
      "Cell \u001b[0;32mIn[17], line 55\u001b[0m, in \u001b[0;36mget_text\u001b[0;34m(query, max_chars)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_text\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m, max_chars: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m---> 55\u001b[0m     urls \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     valid_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     57\u001b[0m     valid_urls \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[10], line 28\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     25\u001b[0m search_box\u001b[38;5;241m.\u001b[39msubmit()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Wait for results and extract links\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Allow time for results to load\u001b[39;00m\n\u001b[1;32m     29\u001b[0m results \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma.result__a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m links \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# def search(query: str) -> List[str]:\n",
    "#     search_url = \"https://html.duckduckgo.com/html/\"\n",
    "#     params = {\n",
    "#         'q': query ,\n",
    "#     }\n",
    "#     headers = {\n",
    "#         'User-Agent': 'Mozilla/5.0'\n",
    "#     }\n",
    "#     try:\n",
    "#         response = requests.post(search_url, data=params, headers=headers, timeout=10)\n",
    "#         response.raise_for_status()\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during DuckDuckGo search for query '{query}': {e}\")\n",
    "#         return []\n",
    "    \n",
    "#     print(response.text)\n",
    "\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#     links = []\n",
    "#     for result in soup.find_all('a', {'class': 'result__a'}, href=True):\n",
    "#         links.append(result['href'])\n",
    "#         if len(links) >= 8:\n",
    "#             break\n",
    "#     print(links)\n",
    "#     return links\n",
    "\n",
    "def extract_text_with_timeout(url: str, max_chars: int = 10000, timeout: int = 10) -> Tuple[str, str]:\n",
    "    def _extract():\n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',\n",
    "            }\n",
    "            response = requests.get(url, headers=headers, timeout=timeout)\n",
    "            if response.status_code == 403:\n",
    "                return \"\", url\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            return text[:max_chars], url\n",
    "        except Exception as e:\n",
    "            return \"\", url\n",
    "\n",
    "    try:\n",
    "        with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "            future = executor.submit(_extract)\n",
    "            return future.result(timeout=timeout)\n",
    "    except TimeoutError:\n",
    "        print(f\"Timeout for {url}\")\n",
    "        return \"\", url\n",
    "\n",
    "def get_text(query: str, max_chars: int = 10000) -> Tuple[str, List[str]]:\n",
    "    urls = search(query)\n",
    "    valid_texts = []\n",
    "    valid_urls = []\n",
    "    \n",
    "    for url in urls:\n",
    "        text, url = extract_text_with_timeout(url)\n",
    "        if text.strip():\n",
    "            valid_texts.append(text)\n",
    "            valid_urls.append(url)\n",
    "        # time.sleep(0.5)  # Respectful delay\n",
    "    \n",
    "    if not valid_texts:\n",
    "        return \"No valid information found.\", []\n",
    "        \n",
    "    return \"\\n\\n\".join(valid_texts), valid_urls\n",
    "\n",
    "\n",
    "\n",
    "# trying with google for funzies - not needed\n",
    "\n",
    "def google_search(query: str, num_results: int =8) -> List[str]:\n",
    "    search_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        \"key\": GOOGLE_API_KEY,\n",
    "        \"cx\": SEARCH_ENGINE_ID,\n",
    "        \"q\": query,\n",
    "        \"num\": num_results,  # Max results (1-10 per request)\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(search_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        results = response.json().get(\"items\", [])\n",
    "        links = [item[\"link\"] for item in results]\n",
    "        return links\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Google search for query '{query}': {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "links = get_text(\"lydia liu princeton cs\")\n",
    "print(links)\n",
    "\n",
    "def get_text_w_google(query: str, max_chars: int = 10000) -> Tuple[str, List[str]]:\n",
    "    urls = google_search(query)\n",
    "    valid_texts = []\n",
    "    valid_urls = []\n",
    "    \n",
    "    for url in urls:\n",
    "        text, url = extract_text_with_timeout(url)\n",
    "        if text.strip():\n",
    "            valid_texts.append(text)\n",
    "            valid_urls.append(url)\n",
    "        # time.sleep(0.5)  # Respectful delay\n",
    "    \n",
    "    if not valid_texts:\n",
    "        return \"No valid information found.\", []\n",
    "        \n",
    "    return \"\\n\\n\".join(valid_texts), valid_urls\n",
    "\n",
    "\n",
    "# get_text_w_google(\"MIT CSAIL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personal_website = client.chat.completions.create(\n",
    "#     model=\"gpt-4o\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are an helpful assitant designed to be factually accurate\"},\n",
    "#         {\"role\": \"user\", \"content\": \"can you give me Princeton Professor Lydia Liu's non-academic intrests\"},\n",
    "#     ]\n",
    "# ).choices[0].message.content\n",
    "\n",
    "# print(personal_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def get_hobbies(name: str) -> Faculty:\n",
    "    a = get_text(name)\n",
    "    base_text = a\n",
    "    \n",
    "    # Stronger and more detailed prompt\n",
    "    prompt = (\n",
    "        \"Based on the following information about the individual, provide a comprehensive and detailed description \"\n",
    "        \"of their hobbies (non-academic interests) and research interests. provide a comprehensive bullet-point list of their non-academic interests.\"\n",
    "        \"Ensure the list \"f\"captures in detail the main hobbies mentioned in the text: \\n\\n{base_text}\\n\\n\" \n",
    "        \"For the non-academic interests, ensure that each hobby/non-academic interest is followed by a reference url in the comma-separated list.\"\n",
    "        \"Very important: if you do not find evidence of any non-academic hobbies, please return an empty list and an empty paragraph.\"\n",
    "        \"highlighting the fun and qualitative aspects of the person's life outside of their professional work. \"\n",
    "        \"If there are multiple people with the same name, please only consider the individual who is a professor at the named university. \"\n",
    "    )\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant that provides detailed and comprehensive descriptions of individuals' hobbies and personal interests based on provided information.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ], \n",
    "            response_format=Faculty\n",
    "        )\n",
    "        hobbies_data = response.choices[0].message.parsed\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing hobbies for {name}: {e}\")\n",
    "    \n",
    "    return hobbies_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing first two PIs: 100%|██████████| 4/4 [00:48<00:00, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched CSV file 'mit_csail_pis_enriched.csv' has been created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # %%\n",
    "# # Load the existing CSV\n",
    "# df = pd.read_csv('mit_csail_pis.csv')\n",
    "\n",
    "# # Initialize new columns\n",
    "# df['gpt_research_interest_paragraph'] = \"\"\n",
    "# df['gpt_research_interest_bullet'] = \"\"\n",
    "# df['gpt_hobbies'] = \"\"\n",
    "# df['gpt_hobbies_bullet'] = \"\"\n",
    "\n",
    "# # Iterate over each PI to fetch and append hobbies data\n",
    "# # for index, row in tqdm(df.iterrows(), total=df.__len__(), desc=\"Processing PIs\"):\n",
    "# for index, row in tqdm(df.head(4).iterrows(), total=4, desc=\"Processing first two PIs\"):\n",
    "#     name = row['Principal Investigator']\n",
    "#     faculty_data = get_hobbies(name)\n",
    "    \n",
    "#     df.at[index, 'gpt_hobbies'] = faculty_data.hobbies\n",
    "#     df.at[index, 'gpt_hobbies_bullet'] = \"; \".join(faculty_data.hobbies_as_commaseparated_list)\n",
    "#     df.at[index, 'gpt_research_interest_paragraph'] = faculty_data.research_interests_paragraph\n",
    "#     df.at[index, 'gpt_research_interest_bullet'] = \"; \".join(faculty_data.research_interests_as_commaseparated_list)\n",
    "\n",
    "# # Save the updated CSV\n",
    "# df.to_csv('mit_csail_pis_enriched.csv', index=False)\n",
    "# print(\"Enriched CSV file 'mit_csail_pis_enriched.csv' has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run above sell for all PIs - tried to make this fater :D\n",
    "# sample_run = get_hobbies(\"ariel procaccia harvard professor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sample_run.hobbies, '\\n\\n\\n', sample_run.hobbies_as_commaseperated_list)\n",
    "\n",
    "# print(\"\\n\\n\\n research interests \\n\\n\\n\")\n",
    "# print(sample_run.research_interests_paragraph, '\\n\\n\\n' ,sample_run.research_interests_as_commaseperated_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
