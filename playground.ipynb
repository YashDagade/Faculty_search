{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'mit_csail_pis.csv' has been created successfully with 131 entries.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def parse_pis(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = [line.strip() for line in file if line.strip()]  # Remove empty lines\n",
    "\n",
    "    pis = []\n",
    "    # Split lines into blocks at 'PI'\n",
    "    blocks = []\n",
    "    current_block = []\n",
    "    for line in lines:\n",
    "        if line == 'PI':\n",
    "            if current_block:\n",
    "                blocks.append(current_block)\n",
    "                current_block = []\n",
    "        else:\n",
    "            current_block.append(line)\n",
    "    if current_block:\n",
    "        blocks.append(current_block)\n",
    "\n",
    "    # Define identifiers to skip (optional)\n",
    "    identifiers = {'Core/Dual', 'Dual/Core', 'Core', 'Dual'}\n",
    "\n",
    "    for block in blocks:\n",
    "        pi = {\n",
    "            'Principal Investigator': '',\n",
    "            'Email': '',\n",
    "            'Phone': '',\n",
    "            'Room No': '',\n",
    "            'Research Interests': ''\n",
    "        }\n",
    "        i = 0\n",
    "        # Check for identifier\n",
    "        if i < len(block) and block[i] in identifiers:\n",
    "            i += 1\n",
    "        # Name\n",
    "        if i < len(block):\n",
    "            pi['Principal Investigator'] = block[i]\n",
    "            i += 1\n",
    "        # Position (e.g., Professor, Associate Professor, etc.) - skipped or stored if needed\n",
    "        if i < len(block):\n",
    "            position = block[i]\n",
    "            i += 1\n",
    "        # Name repeated - skipped\n",
    "        if i < len(block):\n",
    "            repeated_name = block[i]\n",
    "            i += 1\n",
    "        # Parse contact info\n",
    "        while i < len(block) and block[i] in {'e', 'p', 'r'}:\n",
    "            key = block[i]\n",
    "            i += 1\n",
    "            if i < len(block):\n",
    "                value = block[i]\n",
    "                if key == 'e':\n",
    "                    pi['Email'] = value\n",
    "                elif key == 'p':\n",
    "                    pi['Phone'] = value\n",
    "                elif key == 'r':\n",
    "                    pi['Room No'] = value\n",
    "                i += 1\n",
    "        # Parse Research Interests if available\n",
    "        if i < len(block):\n",
    "            # Ensure that the next line is not a new 'PI'\n",
    "            if block[i] != 'PI':\n",
    "                pi['Research Interests'] = block[i]\n",
    "                i += 1\n",
    "        pis.append(pi)\n",
    "\n",
    "    return pis\n",
    "\n",
    "def write_csv(pis, output_file):\n",
    "    fieldnames = ['Principal Investigator', 'Email', 'Phone', 'Room No', 'Research Interests', 'Hobbies']\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for pi in pis:\n",
    "            writer.writerow(pi)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = 'mit_csail_pis.txt'  # Replace with your actual file path\n",
    "    output_csv = 'mit_csail_pis.csv'\n",
    "    pis = parse_pis(input_file)\n",
    "    write_csv(pis, output_csv)\n",
    "    print(f\"CSV file '{output_csv}' has been created successfully with {len(pis)} entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Principal Investigator</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Room No</th>\n",
       "      <th>Research Interests</th>\n",
       "      <th>Hobbies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hal Abelson</td>\n",
       "      <td>hal@mit.edu</td>\n",
       "      <td>253-5856</td>\n",
       "      <td>32-G516</td>\n",
       "      <td>Programming, privacy, App Inventor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ted Adelson</td>\n",
       "      <td>adelson@csail.mit.edu</td>\n",
       "      <td>253-0645</td>\n",
       "      <td>32-310</td>\n",
       "      <td>Vision, touch sensing, robotics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anant Agarwal</td>\n",
       "      <td>agarwal@edx.org</td>\n",
       "      <td>253-1448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Systems, architecture, online learning, edX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pulkit Agrawal</td>\n",
       "      <td>PULKITAG@MIT.EDU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mohammad Alizadeh</td>\n",
       "      <td>alizadeh@csail.mit.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32-G920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Principal Investigator                   Email     Phone  Room No  \\\n",
       "0            Hal Abelson             hal@mit.edu  253-5856  32-G516   \n",
       "1            Ted Adelson   adelson@csail.mit.edu  253-0645   32-310   \n",
       "2          Anant Agarwal         agarwal@edx.org  253-1448      NaN   \n",
       "3         Pulkit Agrawal        PULKITAG@MIT.EDU       NaN      NaN   \n",
       "4      Mohammad Alizadeh  alizadeh@csail.mit.edu       NaN  32-G920   \n",
       "\n",
       "                            Research Interests  Hobbies  \n",
       "0           Programming, privacy, App Inventor      NaN  \n",
       "1              Vision, touch sensing, robotics      NaN  \n",
       "2  Systems, architecture, online learning, edX      NaN  \n",
       "3                                          NaN      NaN  \n",
       "4                                          NaN      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('mit_csail_pis.csv')\n",
    "\n",
    "print(df.__len__())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great his works\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from typing import List, Literal, Optional, Tuple\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "from multiprocessing import Pool\n",
    "from typing import List, Union\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "import threading\n",
    "from functools import partial\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "SEARCH_ENGINE_ID = os.getenv(\"SEARCH_ENGINE_ID\")\n",
    "\n",
    "def search(query: str) -> List[str]:\n",
    "    search_url = \"https://html.duckduckgo.com/html/\"\n",
    "    params = {\n",
    "        'q': query + \"hobbies\"\n",
    "    }\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(search_url, data=params, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during DuckDuckGo search for query '{query}': {e}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = []\n",
    "    for result in soup.find_all('a', {'class': 'result__a'}, href=True):\n",
    "        links.append(result['href'])\n",
    "        if len(links) >= 8:\n",
    "            break\n",
    "    return links\n",
    "\n",
    "def extract_text_with_timeout(url: str, max_chars: int = 10000, timeout: int = 10) -> Tuple[str, str]:\n",
    "    def _extract():\n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',\n",
    "            }\n",
    "            response = requests.get(url, headers=headers, timeout=timeout)\n",
    "            if response.status_code == 403:\n",
    "                return \"\", url\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            return text[:max_chars], url\n",
    "        except Exception as e:\n",
    "            return \"\", url\n",
    "\n",
    "    try:\n",
    "        with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "            future = executor.submit(_extract)\n",
    "            return future.result(timeout=timeout)\n",
    "    except TimeoutError:\n",
    "        print(f\"Timeout for {url}\")\n",
    "        return \"\", url\n",
    "\n",
    "def get_text(query: str, max_chars: int = 10000) -> Tuple[str, List[str]]:\n",
    "    urls = search(query)\n",
    "    valid_texts = []\n",
    "    valid_urls = []\n",
    "    \n",
    "    for url in urls:\n",
    "        text, url = extract_text_with_timeout(url)\n",
    "        if text.strip():\n",
    "            valid_texts.append(text)\n",
    "            valid_urls.append(url)\n",
    "        # time.sleep(0.5)  # Respectful delay\n",
    "    \n",
    "    if not valid_texts:\n",
    "        return \"No valid information found.\", []\n",
    "        \n",
    "    return \"\\n\\n\".join(valid_texts), valid_urls\n",
    "\n",
    "\n",
    "# get_text(\"MIT CSAIL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying with google for funzies - not needed\n",
    "\n",
    "def google_search(query: str, num_results: int =8) -> List[str]:\n",
    "    search_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        \"key\": GOOGLE_API_KEY,\n",
    "        \"cx\": SEARCH_ENGINE_ID,\n",
    "        \"q\": query + \"hobbies\",\n",
    "        \"num\": num_results,  # Max results (1-10 per request)\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(search_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        results = response.json().get(\"items\", [])\n",
    "        links = [item[\"link\"] for item in results]\n",
    "        return links\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Google search for query '{query}': {e}\")\n",
    "        return []\n",
    "\n",
    "# # Example usage:\n",
    "# links = google_search(\"MIT CSAIL\")\n",
    "# print(links)\n",
    "\n",
    "def get_text_w_google(query: str, max_chars: int = 10000) -> Tuple[str, List[str]]:\n",
    "    urls = google_search(query)\n",
    "    valid_texts = []\n",
    "    valid_urls = []\n",
    "    \n",
    "    for url in urls:\n",
    "        text, url = extract_text_with_timeout(url)\n",
    "        if text.strip():\n",
    "            valid_texts.append(text)\n",
    "            valid_urls.append(url)\n",
    "        # time.sleep(0.5)  # Respectful delay\n",
    "    \n",
    "    if not valid_texts:\n",
    "        return \"No valid information found.\", []\n",
    "        \n",
    "    return \"\\n\\n\".join(valid_texts), valid_urls\n",
    "\n",
    "\n",
    "# get_text_w_google(\"MIT CSAIL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"resrach_interests\":\"Professor Ted Adelson\\'s research interests include the development of advanced tactile sensors for robotic manipulation, exploring the intersection of human and machine vision, and creating technologies that enable robots to use touch similarly to humans. He aims to integrate visual and tactile information to enhance robotics capabilities in various applications, from healthcare to manufacturing.\",\"resserach_interests_as_commaseperated_list\":[\"Tactile sensors for robotics\",\"Human vision\",\"Machine vision\",\"Robotic manipulation\",\"AI and deep learning in robotics\"],\"hobbies\":\"In his spare time, Ted enjoys exploring outdoor activities like hiking, as well as engaging in creative projects that blend technology with art.\",\"hobbies_as_commaseperated_list\":[\"Hiking\",\"Creative tech projects\",\"Exploring nature\",\"Photography\"]}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay so now we just google serach for the PI's name followed by social intrests I guess - let me play with this a bit - we can do their name followed by (something something - could be otpimized later for now I am thinking of just Name + Hobbies)\n",
    "\n",
    "# we will than feed that into GPT-40 mini or gemini flash 2 (whichever is faster) and try to summarize the person's social aspects and write a small bio about thier social aspects\n",
    "\n",
    "\n",
    "names = df['Principal Investigator'].tolist()\n",
    "\n",
    "# Faculty type\n",
    "class Faculty(BaseModel):\n",
    "    resrach_interests: str\n",
    "    resserach_interests_as_commaseperated_list: List[str]\n",
    "    hobbies: str\n",
    "    hobbies_as_commaseperated_list: List[str]\n",
    "\n",
    "\n",
    "def get_hobbies(name: str) -> str:\n",
    "    base_text, _ = get_text(name)\n",
    "    hobby_text = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"In a few sentences, describe the hobbies of this person.\"},\n",
    "            {\"role\": \"user\", \"content\": base_text}\n",
    "        ], \n",
    "        response_format=Faculty\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    return hobby_text\n",
    "\n",
    "get_hobbies(\"Ted Adelson\")\n",
    "\n",
    "\n",
    "# I can prompot engineer this further and make this much better - let's do that actually! that's the differecence between good and great - okay let me do that now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
